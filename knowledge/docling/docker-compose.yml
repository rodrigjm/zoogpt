# ============================================================
# Zoocari - Zoo Q&A Chatbot with Local Kokoro TTS
# ============================================================
#
# Quick Start:
#   docker compose up --build
#
# Environment Variables (set in .env or pass directly):
#   - OPENAI_API_KEY (required): OpenAI API key for chat & STT
#   - ELEVENLABS_API_KEY (optional): Fallback TTS provider
#   - TTS_VOICE (optional): Kokoro voice ID (default: af_heart)
#
# ============================================================

services:
  zoocari:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: zoocari-app
    ports:
      - "8501:8501"

    volumes:
      # Persist vector database between container restarts
      - ./data:/app/data

      # Persist Hugging Face model cache (Kokoro, spaCy models)
      # This prevents re-downloading models on container restart
      - zoocari-hf-cache:/app/.cache/huggingface

      # Persist PyTorch cache
      - zoocari-torch-cache:/app/.cache/torch

    environment:
      # Required
      - OPENAI_API_KEY=${OPENAI_API_KEY:?OPENAI_API_KEY is required}

      # Optional: ElevenLabs fallback TTS
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY:-}

      # TTS Configuration (openai is fastest for Docker, kokoro only for native/GPU)
      - TTS_VOICE=${TTS_VOICE:-nova}
      - TTS_PROVIDER=${TTS_PROVIDER:-openai}

      # Python settings for unbuffered logging
      - PYTHONUNBUFFERED=1

      # Hugging Face cache location
      - HF_HOME=/app/.cache/huggingface
      - TORCH_HOME=/app/.cache/torch

    env_file:
      - path: .env
        required: false

    # Restart policy
    restart: unless-stopped

    # Resource limits (adjust based on your hardware)
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # Cloudflare Tunnel (HTTPS for mobile voice support)
  # ============================================================
  # Provides secure HTTPS access required for browser microphone API.
  # See CLOUDFLARE_TUNNEL_SETUP.md for configuration steps.
  #
  # Prerequisites:
  #   1. Create tunnel: cloudflared tunnel create zoocari
  #   2. Add credentials.json to ./cloudflare/
  #   3. Set CLOUDFLARE_TUNNEL_TOKEN in .env (or use credentials file)
  # ============================================================
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: zoocari-tunnel
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN:-}
    volumes:
      # Mount tunnel credentials and config
      - ./cloudflare:/etc/cloudflared:ro
    depends_on:
      - zoocari
    profiles:
      - tunnel  # Only start with: docker compose --profile tunnel up

  # ============================================================
  # Admin Portal - API Backend
  # ============================================================
  # Provides analytics, KB management, and configuration APIs.
  # Shares data volume with main zoocari app.
  # ============================================================
  admin-api:
    build:
      context: ./apps/admin-api
      dockerfile: Dockerfile
    container_name: zoocari-admin-api
    ports:
      - "8000:8000"
    volumes:
      # Share data directory with main app (SQLite DB, LanceDB, config)
      - ./data:/app/data
    environment:
      - PYTHONUNBUFFERED=1
      # Admin credentials (override in .env)
      - ADMIN_USERNAME=${ADMIN_USERNAME:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-zoocari-admin}
      - JWT_SECRET=${JWT_SECRET:-zoocari-jwt-secret-change-in-production}
      # Data paths
      - SESSION_DB_PATH=/app/data/sessions.db
      - LANCEDB_PATH=/app/data/zoo_lancedb
      - CONFIG_PATH=/app/data/config.json
    env_file:
      - path: .env
        required: false
    depends_on:
      - zoocari
    restart: unless-stopped
    profiles:
      - admin  # Start with: docker compose --profile admin up
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # Admin Portal - React Frontend
  # ============================================================
  # SPA dashboard served via nginx, proxies API to admin-api.
  # ============================================================
  admin-web:
    build:
      context: ./apps/admin
      dockerfile: Dockerfile
    container_name: zoocari-admin-web
    ports:
      - "8502:80"
    depends_on:
      - admin-api
    restart: unless-stopped
    profiles:
      - admin  # Start with: docker compose --profile admin up
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# Named volumes for persistent model cache
volumes:
  zoocari-hf-cache:
    name: zoocari-hf-cache
  zoocari-torch-cache:
    name: zoocari-torch-cache
